{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "516c9292",
   "metadata": {},
   "source": [
    "# Beginning\n",
    "+ header\n",
    "+ libraries\n",
    "+ read in data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ec7d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "162c0299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108051"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 34849 + 21995 +45564 +1441 +4202\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ac0e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Purpose:  featurize the sentences, and make a naive bayes classifier\n",
    "##### Author: Julia Cope\n",
    "##### Creation Date: 4/23/23\n",
    "##### Project: A2 NLP - capturing climate claims \n",
    "##### Inputs: \n",
    "##### Inputs: 03_Outputs/04_labeled_sampledata.csv\n",
    "##### Inputs: \n",
    "##### Output: \n",
    "##### Output: \n",
    "##### Output: \n",
    "\n",
    "\n",
    "### libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "#from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import random\n",
    "\n",
    "#import tensorflow_decision_forests as tfdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0d3a85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>ClimateLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Any opinions expressed herein are statements o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Department reasons the NPRM is consistent ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Factors that could cause actual results to dif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[15] [ 1]:             [ 2]:             [ 3]:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Among the changes are enhanced cleaning effort...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  ClimateLabel\n",
       "0  Any opinions expressed herein are statements o...             0\n",
       "1  The Department reasons the NPRM is consistent ...             0\n",
       "2  Factors that could cause actual results to dif...             1\n",
       "3  [15] [ 1]:             [ 2]:             [ 3]:...             0\n",
       "4  Among the changes are enhanced cleaning effort...             0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read in data\n",
    "#input_sentences = pd.read_csv('03_Outputs/04_labeled_sampledata.csv',parse_dates=['Date'])\n",
    "\n",
    "input_sentences = pd.read_csv('03_Outputs/04D_FULL_labeled_sampledata.csv',parse_dates=['Date'])\n",
    "del input_sentences['climate_score']\n",
    "del input_sentences['likely']\n",
    "del input_sentences['Date']\n",
    "del input_sentences['index']\n",
    "del input_sentences['company']\n",
    "del input_sentences['Year']\n",
    "input_sentences['sentences'] = input_sentences['sentences'].astype(str)\n",
    "input_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27c36651",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentences= input_sentences.rename(columns = {'sentences':'text', 'ClimateLabel':'labels'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bd46637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Any opinions expressed herein are statements o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Department reasons the NPRM is consistent ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Factors that could cause actual results to dif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[15] [ 1]:             [ 2]:             [ 3]:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Among the changes are enhanced cleaning effort...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  Any opinions expressed herein are statements o...       0\n",
       "1  The Department reasons the NPRM is consistent ...       0\n",
       "2  Factors that could cause actual results to dif...       1\n",
       "3  [15] [ 1]:             [ 2]:             [ 3]:...       0\n",
       "4  Among the changes are enhanced cleaning effort...       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65cb7ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dataset = Dataset.from_pandas(input_sentences)\n",
    "in_dataset = in_dataset.train_test_split(test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ca1c3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 1440\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 360\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f89fba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train)\n",
    "test_dataset = Dataset.from_pandas(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2698fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentences[\"Words Per sent\"] = input_sentences[\"text\"].str.split().apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc6a9f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## make sure that the length of the sentences/documents are smaller than 512 tokens, which is the max of a transfomer\n",
    "\n",
    "input_sentences.boxplot(\"Words Per sent\", by=\"labels\", grid=False, showfliers=False,\n",
    "           color=\"black\")\n",
    "plt.suptitle(\"\")\n",
    "#plt.xlabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8d29285",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96aaf08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "def4717b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_output\n",
    "PR_encoded = in_dataset.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7521aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1440\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 360\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PR_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daa7f9d",
   "metadata": {},
   "source": [
    "# create a BERT classifier\n",
    "\n",
    "+ load pretrained bert tokenizer and model\n",
    "+ tokenize input sentences (labeled set)\n",
    "+ change into tensorflow dataset datatype\n",
    "+ compile and train model\n",
    "+ evaluate model on prelabeled test data (get recall, f1 score)\n",
    "+ extrapolate model onto unlabeled data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "271ad1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_labels = 2\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c6604c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07b691eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "batch_size = 2\n",
    "logging_steps = len(PR_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{model_ckpt}-finetuned-PR\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=2,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "818384ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='1440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   6/1440 00:42 < 4:14:40, 0.09 it/s, Epoch 0.01/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17640\\1982602715.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                   \u001b[0meval_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPR_encoded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"test\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                   tokenizer=tokenizer)\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1660\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m         )\n\u001b[1;32m-> 1662\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1663\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1664\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1927\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1928\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1929\u001b[1;33m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1931\u001b[0m                 if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2715\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2717\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2719\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             )\n\u001b[1;32m--> 487\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, \n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=PR_encoded[\"train\"],\n",
    "                  eval_dataset=PR_encoded[\"test\"],\n",
    "                  tokenizer=tokenizer)\n",
    "trainer.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9edcd15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a1dc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe16560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0950d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "tf_model = (TFAutoModelForSequenceClassification\n",
    "            .from_pretrained(model_ckpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a4d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PR_encoded[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ad0ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a6606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_columns = tokenizer.model_input_names\n",
    "\n",
    "\n",
    "tf_train_dataset = PR_encoded[\"train\"].to_tf_dataset(\n",
    "    columns=tokenizer_columns, label_cols=[\"ClimateLabel\"], shuffle=True,\n",
    "    batch_size=32)\n",
    "tf_eval_dataset = PR_encoded[\"test\"].to_tf_dataset(\n",
    "    columns=tokenizer_columns, label_cols=[\"ClimateLabel\"], shuffle=False,\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea53802",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce513207",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    loss=tf.keras.losses.BinaryFocalCrossentropy(apply_class_balancing=True),\n",
    "    metrics=tf.keras.metrics.Recall())\n",
    "\n",
    "tf_model.fit(tf_train_dataset, validation_data=tf_eval_dataset, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7144b79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d9e1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e5cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "train_encoded = train_dataset.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "test_encoded = test_dataset.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de20fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9be12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0990fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce55f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32 \n",
    "\n",
    "# The column names to convert to TensorFlow tensors\n",
    "tokenizer_columns = tokenizer.model_input_names\n",
    "\n",
    "tf_train_dataset = train_encoded.to_tf_dataset(\n",
    "    columns=tokenizer_columns, label_cols=[\"ClimateLabel\"], shuffle=True,\n",
    "    batch_size=batch_size)\n",
    "tf_eval_dataset = test_encoded.to_tf_dataset(\n",
    "    columns=tokenizer_columns, label_cols=[\"ClimateLabel\"], shuffle=False,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f01be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83b5d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/getting_started/faq/#how-can-i-freeze-layers-and-do-finetuning\n",
    "\n",
    "tf_model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_output\n",
    "import tensorflow as tf\n",
    "\n",
    "tf_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    loss=tf.keras.losses.BinaryFocalCrossentropy(apply_class_balancing=True),\n",
    "    metrics=tf.keras.metrics.Recall())\n",
    "\n",
    "tf_model.fit(tf_train_dataset, validation_data=tf_eval_dataset, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caad72ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c372147",
   "metadata": {},
   "source": [
    "## Get confusion matrix\n",
    "+ get predicted output for the test set from the .predict() method\n",
    "+ you can get all the metrics directly from the above object\n",
    "+ also get the y_pred so that we can plot the cnfusion matrix\n",
    "+ get confusion matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d786312",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_np = test_encoded['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27c75eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa4eaff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1d2f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c82058",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a497df",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_output = tf_model.predict(tf_eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d37aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.evaluate(tf_eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef862e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d6c530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.argmax(preds_output.logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f995eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae36453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate model with \n",
    "y_pred = np.round(model.predict([X_encoded['input_ids'], X_encoded['attention_mask']]))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb9aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e7da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae829b33",
   "metadata": {},
   "source": [
    "## Save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a5f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# assume you have a functional model called `my_model`\n",
    "# save the model to a file called `my_model.h5`\n",
    "tf_model.save('07A_distilbert_classifier',save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753687c2",
   "metadata": {},
   "source": [
    "# Save the model \n",
    "+ save the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b94122",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47193268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# assume you have a functional model called `my_model`\n",
    "# save the model to a file called `my_model.h5`\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1a7826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from transformers import TFBertModel\n",
    "\n",
    "# Define a dictionary to map the custom object name to the actual class\n",
    "custom_objects = {'TFBertModel': TFBertModel}\n",
    "\n",
    "# Load the saved model from the file, passing the custom_objects dictionary to the 'custom_objects' argument\n",
    "loaded_model = load_model('my_model.h5', custom_objects=custom_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d8cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d837cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24317cfd",
   "metadata": {},
   "source": [
    "# Use model to predict labels of unseen data \n",
    "+ load unseen data\n",
    "+ tokenize sentences \n",
    "+ predict labels\n",
    "+ turn probabilities into binary labels\n",
    "+ add predicted labels to the df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21e5070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load new data for prediction\n",
    "unlabeled_data_df = pd.read_csv('03_Outputs/04_unlabeled_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e0132a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unlabeled_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13d3c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows where the year column value is greater than 2017\n",
    "df_filtered = unlabeled_data_df[unlabeled_data_df['Year'] > 2017]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c844d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c5a9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#18 minutes\n",
    "\n",
    "# Tokenize input sentences for new data\n",
    "X_new_encoded = tokenizer(df_filtered['sentences'].tolist(), max_length=128, padding=True, truncation=True, return_tensors='tf')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8fe20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for new data\n",
    "#y_pred = model.predict([X_new_encoded['input_ids'], X_new_encoded['attention_mask']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4970db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert probability scores to binary labels\n",
    "y_pred_binary = np.round(y_pred).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dae18b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predicted labels to new_df\n",
    "df_filtered['predicted_label'] = y_pred_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710d787d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
